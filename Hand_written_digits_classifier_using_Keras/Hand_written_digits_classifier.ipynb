{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MNIST dataset grayscale image classifier is desgined to classify handwritten digits (28 * 28 pixels) into 10 categories (0 to 10). \n",
    "\n",
    "60,000 - Training images\n",
    "10,000 - Testing images\n",
    "\n",
    "Program is written mainly using Keras library\n",
    "\n",
    "MNIST dataset is a mutidimensional Numpy arrays called as tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "#Keras has perloaded MNIST data in the form of a set of four Numpy arrays\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#Forming 2 tuples for training and test datasets\n",
    "#mnist.load_data() it loads 4 numpay arrays and are assigned to tuples\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[5 0 4 ... 5 6 8]\n",
      "3\n",
      "(10000, 28, 28)\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "#Images are encoded as Numpy arrays and labels are an array of digits, ranging from 0 to 9\n",
    "#Images and Labels have a one-to-one correspondence\n",
    "\n",
    "#let's look at the data\n",
    "print(train_images.shape)   #to get sahpe; no elements in each axes\n",
    "print(train_labels)\n",
    "print(train_images.ndim)    #to get dimension of tensor\n",
    "\n",
    "#For test dataset\n",
    "print(test_images.shape)    #to get sahpe; no elements in each axes\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying  the fourth digit\n",
    "digit = train_images[3]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap = plt.cm.binary)      #imshow method to show image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the network; layers are data processing modules that we can think as filters of data\n",
    "\n",
    "from keras import models  #to make sequential type networks\n",
    "from keras import layers  #to add layers to network\n",
    "\n",
    "#Adding layers to network; Dense here is used to define fully connected layers. \n",
    "#First layer has 512 nodes that will take input of 784 (28*28) pixel values to pass it to next layer.\n",
    "#Last layer is 10-way softamx layer, it means it will return array of 10 probability scores (summing to 1).\n",
    "\n",
    "#layers.Dense takes only 2D arrays\n",
    "#Layers can be interpreted as a function, which takes 2D tensor\n",
    "\n",
    "network = models.Sequential()   \n",
    "network.add(layers.Dense(512, activation = 'relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation = \"softmax\"))\n",
    "\n",
    "#output = relu(dot(W, input) + b     W-2D tenosr, b- vector\n",
    "#Explaniation of above layer.Dense function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSProp: Root Mean Square Propagation\n",
    "#Now compiliing the network\n",
    "network.compile(optimizer = 'rmsprop',                #Mechanism by which network will update itself\n",
    "                loss = 'categorical_crossentropy',    #To measure the performance of the network \n",
    "                metrics = ['accuracy'])               #Metrics to monitor during testing and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before training the network, we have to reshape the data in a shape that network expects and scaling all values in [0, 1] interval\n",
    "#from (60000, 28, 28) type unit8  with values [0,255] interval to float array (60000, 28 * 28) with values range between[0, 1]\n",
    "\n",
    "#Preparing the image data\n",
    "train_images = train_images.reshape((60000, 28 * 28))  #to change the shape\n",
    "train_images = train_images.astype('float32') / 255   #to change the data type and values are converted in the range 0 to 1\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))  #to change the shape\n",
    "test_images = test_images.astype('float32') / 255   #to change the data type and values are converted in the range of 0 to1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to categorically encode the labels as all ten-values are different types of categories\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)  #Encoding train_labels\n",
    "test_labels = to_categorical(test_labels)    #Encoding test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.2583 - acc: 0.9254\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.1044 - acc: 0.9693\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0693 - acc: 0.9790\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 91us/step - loss: 0.0499 - acc: 0.9851\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0366 - acc: 0.9890\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0287 - acc: 0.9912\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0215 - acc: 0.9938\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.0170 - acc: 0.9950\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0123 - acc: 0.9966\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.0101 - acc: 0.9970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13532cd9ac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the network with fit method on network with train_images and trian_labels\n",
    "network.fit(train_images, train_labels, epochs = 10, batch_size = 128)\n",
    "\n",
    "#loss: over training data\n",
    "#acc: over training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/step\n",
      "test_acc:  0.9808\n"
     ]
    }
   ],
   "source": [
    "#Network's accuracy on test data: evaluate method is used to test on test dataset \n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print(\"test_acc: \", test_acc)\n",
    "\n",
    "#Less test-set accuracy is due to overfitting of model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
